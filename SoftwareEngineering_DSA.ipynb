{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures and Algorithms\n",
    "\n",
    "- [LaTex](https://www.malinc.se/math/latex/basiccodeen.php)\n",
    "\n",
    "Before we start the course, we will discuss some of the basics\n",
    "\n",
    "- Introduction to Big-O complexity \n",
    "- Introduction to recursion \n",
    "\n",
    "Before we talk about Big-O, it is important that we first understand what exactly an \"algorithm\" is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An algorithm can be seen as a recipe for a computer to follow. It's a set of instructions that a computer will follow step-by-step to solve a problem. An algorithm takes an inpute and produce an output. \n",
    "\n",
    "For example, let's say  you had a non-empty array of positive integers called `nums`, and you wanted to answer the question: \"what is the largest number in `nums` ?\".\n",
    "\n",
    "- To answer this question, you would write an algorithm that takes an array called `nums` as **input** and **outputs** the largest number in `nums`. Here is an example of such an algorithm:\n",
    "\n",
    "1) Create a variable `maxNum` and initialize it to `0`.\n",
    "2) Iterate over each element `num` in `nums`.\n",
    "3) If `num` is greater than `maxNum`, update `maxNum = num`.\n",
    "4) Output `maxNum`. \n",
    "\n",
    "Here, we have written down a set of instructions that when followed, will solve the problem. We can now implement these instructions in code so that a computer can quickly solve the problem. There are some important requirements for algorithms:\n",
    "\n",
    "* Algorithms should be **deterministic**. Given the same input, the algorithm should **always** produce the same **output**. Basically, there shouldn't be any randomness.\n",
    "* The algorithm should be correct for any arbitrary valid **input**. In our example, we said that `nums` is a non-empty array of positive integers. There are infinitely many of such arrays, and our algorithm works for **all** of them. Note that if `nums` had negative numbers, the input would be invalid since we stated the integers are positive. In fact, our algorithm would actually break because we initialized `maxNum` to 0, so if all of `nums` was negative, we would incorrectly output `0`.\n",
    "\n",
    "<p>\n",
    "\n",
    "---\n",
    "\n",
    "**Big-O**\n",
    "\n",
    "Big-O is a notation used to describe the computational complexity of an algorithm. The computational complexity is split into two parts: \n",
    "\n",
    "1) Time complexity - the amount of time the algorithms needs to run relative to input size\n",
    "2) Space complaxity - the amount of memory allocated by the algorithm relative to input size\n",
    "\n",
    "\n",
    "**Typically, people care about the time complexity more than the space complexity, but both are important to know**.\n",
    "\n",
    "<p>\n",
    "\n",
    "There are some common assumptions that we make. Wehen dealing with integers, the larger t he integer, the more time operations like addition, multiplication or printing will take. While this **is** relevant in theory, we typically ignore this fact because the difference is practically very small, and treat all integers the same. If you are given an array of integers as an input, the only variable you would ues is _n_ to denote the length of the array. Technically, you could introduce another variable, let's say _k_ which denotes the average value of the integers in the array. However, nobody does this. \n",
    "\n",
    "<p>\n",
    "\n",
    "Here are some example of complexities:\n",
    "\n",
    "* $O(n)$\n",
    "* $O(n^{2})$\n",
    "* $O(2^{n})$\n",
    "* $O(log n)$\n",
    "* $O(n.m)$\n",
    "\n",
    "<p>\n",
    "\n",
    "You might be thinking, what is _m_ ? Remember: we define the variables. As these are simple examples with no associated problem, _m_ could denote any arbitrary variable. For example, we could have a problem where the input is two arrays. _n_ could denote the length of one while _m_ denotes the length of the other.\n",
    "\n",
    "<p>\n",
    "\n",
    "**Calculating complexity**\n",
    "\n",
    "Using the above example (find the largest number in `nuums`), we have a time complexity of **O(n)**. The algorithm involves iterating over each elements in `nums`, so if we define _n_ as the length of `nums`, ou algorithm uses approximately _n_ steps. If we pass an array with a length of `10`, it will perform approximately `10` steps. If we pass an array with a length of `10,000,000,000`, it will perform approximately `10,000,000,000` steps. \n",
    "\n",
    "**NOTE:**\n",
    "- Being able to analyze an algorithm and calculate it's time and space complexity is a crucial skill. Interviewers will **almost always** ask you for your algorithm's complexity to check that you actually understand your algorithm and didn't just memorize/copy the code. Being able to analyze an algorithm also enables you to determine what parts of it can be improved. \n",
    "\n",
    "---\n",
    "\n",
    "**Rules**\n",
    "\n",
    "There are a few rules when it comes to calculating complexity. First, **we ignore constants**. That means $O(9999999n) = O(8n) = O(n) = O(\\frac{n}{500})$. Why do we do this? Imagine you had two algorithms. Algorithm A uses approximately _n_ operations and algorithm B uses approximately _5n_ operations. \n",
    "\n",
    "<p>\n",
    "\n",
    "When _n_ = 100, algorithm A uses 100 operations and algorithm B uses 500 operations. What happens if we double _n_ ? Then algorithm A uses 200 operations and algorithm B uses 1000 operations. As you can see, When we double the value of _n_, both algorithms require double the amount of operations. If we were to _10x_ the value of _n_, then both algorithms would require _10x_ more operations.\n",
    "\n",
    "<p>\n",
    "\n",
    "Remember: the point of complexity is to analyze the algorithm **as the input changes**. We don't care that algorithm B is _5x_ slower than algorithm A. For both algorithms, as the input size increases, the number of operations required increases **linearly**. That's what we care about. Thus, both algorithms are **O(n)**.\n",
    "\n",
    "<p>\n",
    "\n",
    "The second rule is that we consider the complexity as the variables **tend to infinity**. When we have additions/subtraction between terms of the **same variable, we ignore all terms except the most powerful one**.\n",
    "\n",
    "For example, $O(2^{n} + n^{2} - 500) = O(2^{n})$. Why? Because as _n_ tends to infinity, $2^{n}$ becomes so large that the other two terms are effectively zero in comparison. \n",
    "\n",
    "Let's say that we had an algorithm that required _n_ + 500 operations. It has a time complexity of $O(n)$. When _n_ is small, let's say n = 5, the +500 term is very significant - but we don't care about that. We need to perform the analysis as if _n_ is tending toward infinity, and in that scenario, the 500 is nothing.\n",
    "\n",
    "<p>\n",
    "\n",
    "**NOTE:**\n",
    "* The best complexity possible is **O(1)**, called \"constant time\" or \"constant space\". it means that the algorithm ALWAYS uses the same amount of resources, regardless of the input.\n",
    "\n",
    "Note that a constant time complexity doesn't neccessarily mean that an algorithm is fast $(O(5000000) = O(1))$, it just means that it's runtime is independent of the input size. \n",
    "\n",
    "<p>\n",
    "\n",
    "When talking about complexity, there are normally three cases:\n",
    "\n",
    "* Best case scenario \n",
    "* Average case \n",
    "* Worst case scenario \n",
    "\n",
    "<p>\n",
    "\n",
    "In most algorithms, all three of these will be equal, but some algorithms will have them differ. If you have to choose only one to represent the algorithm's time or space complexity, never choose the best case scenario. It is most correct to use the worst case scenario, but you should be able to talk about the difference between the cases. \n",
    "\n",
    "<p>\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximumNumber(nums):\n",
    "    \"\"\"\n",
    "    : create a variable `maxNum` and initialize it to `0`\n",
    "    : Iterate over each element `num` in `nums` \n",
    "    : If `num` is greater than `maxNum`, update `maxNum = num`\n",
    "    : Output `maxNum`\n",
    "    \"\"\"\n",
    "    maxNum = 0\n",
    "\n",
    "    for num in nums:\n",
    "        if num > maxNum:\n",
    "            maxNum = num \n",
    "\n",
    "    return maxNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "#test \n",
    "nums = [2, 5, 20, 50, 200, 120, 180]\n",
    "\n",
    "sol = maximumNumber(nums)\n",
    "print(sol)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing time complexity \n",
    "\n",
    "Let's look at some example algorithms in pseudo-code and talk about their time complexities.\n",
    "\n",
    "```\n",
    "// Given an integer array \"arr\" with length n,\n",
    "\n",
    "for (int num: arr) {\n",
    "    print(num)\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "This algorithms has a time complexity of $O(n)$. In each for loop iteration, we are performing a print, which costs $O(1)$. The for loop iterates $n$ times, which gives a time complexity of $O(1.n)= O(n)$.\n",
    "\n",
    "```\n",
    "// Given an integer array \"arr\" with length n,\n",
    "\n",
    "for (int num: arr) {\n",
    "    for (int i = 0; i < 500,000; i++) {\n",
    "        print(num)\n",
    "    }\n",
    "}\n",
    "```\n",
    "This algorithm has a time complexity of $O(n)$. In each inner for loop iteration, we are performing a print, which costs $O(1)$. This for loop iterates 500,000 times, which means each outer for loop iteration costs $O(500000) = O(1)$. The outer for loop iterates $n$ times, which gives a time complexity of $O(n)$.\n",
    "\n",
    "<p>\n",
    "\n",
    "Even though the first two algorithms technically have the same time complexity, in reality the second algorithm is **much** slower than the first one. It's correct to say that the time complexity is $O(n)$, but it's important to be able to discuss the difference between practicality and theory. \n",
    "\n",
    "```\n",
    "// Given an integer array \"arr\" with length n,\n",
    "\n",
    "for (int num: arr) {\n",
    "    for (int num2: arr) {\n",
    "        print(num * num2)\n",
    "    }\n",
    "} \n",
    "```\n",
    "This algorithm has a time complexity of $O(n^{2})$. In each inner for loop iteration, we are performing a multiplication and print, which cost both cost $O(1)$. The inner for loop runs $n$ times, which means each outer for loop iteration costs $O(n)$. The outer for loop runs $O(n)$ times, which gives a time complexity of $O(n.n) = O(n^{2})$.\n",
    "\n",
    "<p>\n",
    "\n",
    "```\n",
    "// Given integer arrays \"arr\" with length n and \"arr2\" with length m,\n",
    "\n",
    "for (int num: arr) {\n",
    "    print(num)\n",
    "}\n",
    "for (int num: arr) {\n",
    "    print(num)\n",
    "}\n",
    "for (int num: arr2) {\n",
    "    print(num)\n",
    "}\n",
    "```\n",
    "\n",
    "This algorithm has a time complexity of $O(n+m)$. The first two for loops both cost $O(n)$, whereas the final for loop costs $O(m)$. This gives a time complexity of $O(2n+m) = O(n+m)$.\n",
    "\n",
    "```\n",
    "// Given an integer array \"arr\" with length n,\n",
    "\n",
    "for (int i = 0; i < arr.length; i++) {\n",
    "    for (int j = i; j < arr.length; j++) {\n",
    "        print(arr[i] + arr[j])\n",
    "    }\n",
    "}\n",
    "```\n",
    "This algorithm has a time complexity of $O(n^{2})$. The inner for loop is dependent on what iteration the outer for loop is currently on. The first time the inner for loop is run it runs $n$ times. The second time, it runs $n-1$ times, then $n-2$, $n-3$, and so on.\n",
    "\n",
    "<p>\n",
    "\n",
    "That means the total iterations is $1 + 2 + 3 + 4 + ... + n$, which is the partial sum of [this series](https://en.wikipedia.org/wiki/1_%2B_2_%2B_3_%2B_4_%2B_%E2%8B%AF#Partial_sums), which is equal to $\\frac{n.(n+1)}{2} = \\frac{n^{2}+n}{2}$. In big-O, this is $O(n^{2})$ because the addition term in the numerator and the constant term in the denominator are both ignored.\n",
    "\n",
    "<p>\n",
    "\n",
    "### Logarithm time\n",
    "\n",
    "A logarithm is the inverse operation to exponents. The time complexity $O(logn)$ is called logarithmic time and is **extremely fast**. A common time complexity is $O(n.logn)$, which is reasonably fast for most problems and also the time complexity of efficient sorting algorithms. \n",
    "\n",
    "Typically, the base of the logarithm will be `2`. This means that if your input is size $n$, then the algorithm will perform $x$ operations, where $2^{x} = n$. However, the base of the logarithm [doesn't actually matter](https://stackoverflow.com/questions/1569702/is-big-ologn-log-base-e/1569710#1569710) for big $O$, since all algorithms are related by a constant factor.\n",
    "\n",
    "$O(logn)$ means that somewhere in your algorithm, the input is being reduced by a percentatge at every step. A good example of this is binary search, which is a searching algorithm that runs in $O(logn)$ time (there is a chapter dedicated to binary search later on). With binary search, we initially consider the entire input ($n$ elements). After the first step, we only consider $n/2$ elements. After the second step, we only consider $n/4$ elements, and so on. At each step, we are reducing our search space by `50%`, which gives us a logarithmic time complexity.\n",
    "\n",
    "<p>\n",
    "\n",
    "### Analyzing space complexity\n",
    "\n",
    "When you initialize variables like arrays or strings, your algorithm is allocating memory. We never count the space used by the input (it is bad practice to modify the input), and usually don't count the space used by the output (the answer) unless an interviewer asks us to.\n",
    "\n",
    "```\n",
    "In the below examples, the code is only allocating memory so that we can analyze the space complexity, so we will consider everything we allocate as part of the space complexity (there is no \"answer\").\n",
    "```\n",
    "\n",
    "```\n",
    "// Given an integer array \"arr\" with length n\n",
    "for (int num: arr) {\n",
    "    print(num)\n",
    "}\n",
    "```\n",
    "This algorithm has a space complexity of $O(1)$. The only space allocated is an integer variable `num`, which is constant relative to $n$.\n",
    "\n",
    "```\n",
    "// Given an integer array \"arr\" with length n\n",
    "array doubleNums = int[]\n",
    "for (int num: arr) {\n",
    "    doubleNums.add(num * 2)\n",
    "}\n",
    "```\n",
    "This algorithm has a space complexity of $O(n)$. The array `doubleNums` stores $n$ integers at the end of the algorithm.\n",
    "\n",
    "```\n",
    "// Given an integer array \"arr\" with length n\n",
    "array nums = int[]\n",
    "int oneHundredth = n / 100\n",
    "\n",
    "for (int i = 0; i < oneHundredth; i++) {\n",
    "    nums.add(arr[i])\n",
    "}\n",
    "```\n",
    "This is algorithm has a space complexity of $O(n)$. The array `nums` stores the first 1% of numbers in `arr`. This gives a space complexity of $O(\\frac{n}{100}) = O(n)$.\n",
    "\n",
    "```\n",
    "// Given integer arrays \"arr\" with length n and \"arr2\"\n",
    "Array grid = int[n][m]\n",
    "for (int i = 0; i < arr.length; i++) {\n",
    "    for (int j = 0; j < arr2.length; j++) {\n",
    "        grid[i][j] = arr[i] * arr2[j]\n",
    "    }\n",
    "}\n",
    "```\n",
    "This algorithm has a space complexity of $O(n.m)$. We are creating a `grid` that has dimensions $n.m$.\n",
    "\n",
    "**NOTE:**\n",
    "* In this course, we will talk extensively about time and space complexity. If it's a new concept to you, don't worry - with practice, you will become more and more comfortable with analyzing algorithms on your own. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to recursion \n",
    "\n",
    "* Recursion is a problem solving method. In code, recursion is implemented using a function that calls itself. \n",
    "\n",
    "The opposite of a recursive algorithm would be an **iterative algorithm**. There [is a branch](https://en.wikipedia.org/wiki/Computability_theory) of study that proves that any iterative algorithm can be written recursively. While iterative algorithms use `for loops and while loops` to simukate repetition, recursive algorithms use function calls to simulate the same logic. \n",
    "\n",
    "Let's say we wanted to print the number from 1 to 10. Here's some pseudocode for an iterative algorithm:\n",
    "\n",
    "```\n",
    "for (int i = 1; i < 10; i++) {\n",
    "    print(i)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#print 1 to 10, starting from 1\n",
    "for i in range(1, 11):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's some pseudocode for an equivalent recursive algorithm:\n",
    "\n",
    "```\n",
    "function fn(i):\n",
    "    print(i)\n",
    "    fn(i + 1)\n",
    "    return \n",
    "\n",
    "fn(1)\n",
    "```\n",
    "\n",
    "**NOTE:** This function will run indefinitely as there is no base code to terminate the function. \n",
    "\n",
    "* Each call to `fn` first prints `i` (which starts at 1), and then calls `fn` again but incrementing `i` (to print the next number).\n",
    "\n",
    "`The first function call prints 1, then calls fn(2). In fn(2), we print 2, then call fn(3), and so on.`\n",
    "\n",
    "<p>\n",
    "\n",
    "However, this code is actually wrong. Do you see the problem? The functio calls will never stop! Running this code would print natural numbers (positive integers) infinitely (or until the computer explode). The `return` line never gets reached because `fn(i + 1)` comes before it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_fun(i):\n",
    "    print(i)\n",
    "    recursive_fun(i + 1)\n",
    "    return \n",
    "\n",
    "#recursive_fun(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize the function and stop it from running indefinitely and stack overflow. we can implement a break when it reaches a base case.\n",
    "\n",
    "We need what is called a **base case** to make the recursion stop. Base cases are conditions at the start of recursive functions that terminate the calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "def recursive_func(i):\n",
    "    if i > 10:\n",
    "        return \n",
    "    print(i)\n",
    "    recursive_func(i + 1)\n",
    "    return \n",
    "\n",
    "recursive_func(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we call `fn(10)`, we print `10` and call `fn(11)`. In the `fn(11)` call, we trigger the base case and return. So now we are back in the call to `fn(10)` and move to the next line, which is the return statement. This makes us return back to the `fn(9)` call and so on, until we eventually return from the `fn(1)` call and the algorithm terminates. \n",
    "\n",
    "An important thing to understand about recursion is the **order** in which the code runs - the order in which the computer executes instructions. With an iterative program, it's easy - start at the top, and go line by line. With recursion, it can get confusing because calls can cascade on top of each other. Let's print numbers again, but this time only up to 3. Let's also add another print statement and number the lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "End of call where i = 3\n",
      "End of call where i = 2\n",
      "End of call where i = 1\n"
     ]
    }
   ],
   "source": [
    "def fn(i):\n",
    "    if i > 3:\n",
    "        return \n",
    "    \n",
    "    print(i)\n",
    "    fn(i + 1)\n",
    "    print(f\"End of call where i = {i}\")\n",
    "    return \n",
    "\n",
    "fn(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the line where we print text is executed in reverse order. The original call `fn(1)` first prints `1`, then calls to `fn(2)`, which prints `2`, then calls to `fn(3)`, which prints `3`, then calls to `fn(4)`. **Now, this the important part:** how recursion \"moves\" back \"up\". `fn(4)` triggers the base case, which returns. We are now back in the function call where `i = 3` and line **4** has finished, so we move to line **5** which prints `End of call where i = 3`. Once that line runs, we move to the next line, which is a `return`. Now, we are back in the function call where `i = 2` and **line 4** line has finshed, so again we move to the next line and print `End of call where i = 2`. This repeats until the original function call to `fn(1)` returns. \n",
    "\n",
    "<p>\n",
    "\n",
    "Note that each function call also has its own scope. So in the example above, when we call `f(3)`, there are 3 \"versions\" of `i` simultaneously. The first call has `i = 1`, the second call has `i = 2`, and the third call has `i = 3`. Let's say that we were to do `i += 1` in the `f(3)` call. Then `i` becomes `4`, but **only** in the `f(3)` call. The other 2 \"versions\" of `i` are unaffected because they are in different scopes. \n",
    "\n",
    "<p>\n",
    "\n",
    "### Breaking problems down\n",
    "\n",
    "This printing example is pretty pointless - it's easier to use a for loop if you just want to print numbers. Where recursion shines is when you use it to break down a problem into \"subproblems\", whose solutions can then be combined to solve the original problem. \n",
    "\n",
    "Let's look at the [Fibonacci numbers](https://en.wikipedia.org/wiki/Fibonacci_sequence). The Fibonacci numbers are a sequence of numbers starting with `0, 1`. Then, each number is defined as teh sum of the previous two numbers. The first few Fibonacci numbers are `0, 1, 1, 2, 3, 5, 8`. More formally we have \n",
    "\n",
    "$F_{n} = F_{n-1} + F_{n-2}$\n",
    "\n",
    "This is called a **recurrence relation** - it's an equation that connected the terms together. \n",
    "\n",
    "Let's use a pseudocode to write a function `F(n)` that returns the $n^{th}$ Fibonacci number (0 indexed). `Don't forget we need base cases with any recursive function`. In this case, the base cases are explicitly defined: `F(0) = 0`, and `F(1) = 1` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return n \n",
    "    \n",
    "    oneback = fib(n - 1)\n",
    "    twoback = fib(n - 2)\n",
    "\n",
    "    return oneback + twoback\n",
    "\n",
    "fib(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sat that we wanted to find `F(3)`. Upon calling `F(3)`, we would see the following flow, with each indentation level representing a function call's scope:\n",
    "\n",
    "```\n",
    "oneBack = fib(2)\n",
    "    oneBack = fib(1)\n",
    "        fib(1) = 1\n",
    "    twoBack = fib(0)\n",
    "        fib(0) = 0\n",
    "    fib(2) = oneBack + twoBack = 1\n",
    "twoBack = fib(1)\n",
    "    fib(1) = 1\n",
    "fib(3) = oneBack + twoBack = 2\n",
    "```\n",
    "\n",
    "* As you can see, we took the original problem `fib(3)`, and broke it down into two smaller subproblems - `F(2)` and `F(1)`. By combining the recurrence relation and base cases, we can solve the subproblems and use those solutions to solve the original problem. \n",
    "\n",
    "This is the most common use of recursion - you have your recursive function **return the answer to the problem you're trying to solve for a given input**. In this example, the problem we're trying to solve for a given input is \"What is the $n^{th}$ Fibonacci number ?\" As such, we designed our function to return a Fibonacci number, according to the input $n$. By determining the base cases and a recurrence relation, we can easily implement the function. \n",
    "\n",
    "<p>\n",
    "\n",
    "By following this idea, solving the subproblems is easy - if we wanted the 100th Fibonacci number, we know by definition that it is the sum of the 99th and 98th Fibonacci number. On the function call to `F(100)`, we know that calling `F(99)` and `F(98)` will give us those numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fibonacci(n, memo={}):\n",
    "    \"\"\"\n",
    "    :optimized Fibonnaci function\n",
    "    \"\"\"\n",
    "    if n <= 1:\n",
    "        return 0\n",
    "    \n",
    "    if n not in memo:\n",
    "        memo[n] = fibonacci(n - 1, memo) + fibonacci(n - 2, memo)\n",
    "        \n",
    "    return memo[n]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
